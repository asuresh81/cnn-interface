{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G-7jMzCllcmP"
   },
   "source": [
    "Reference for image segmentation: \n",
    "1. [Code](https://github.com/nikhilroxtomar/UNet-Segmentation-in-Keras-TensorFlow/blob/master/unet-segmentation.ipynb)\n",
    "2. Paper: [https://arxiv.org/abs/1505.04597](https://arxiv.org/abs/1505.04597)\n",
    "3. Paper: [https://doi.org/10.1371/journal.pcbi.1005177](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005177)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sQFuxuMosJ9G"
   },
   "source": [
    "Part 1: Image Segmentation by CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tjH9nAXtRXwB"
   },
   "source": [
    "Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8vi8zzaERUmt"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from skimage import img_as_float\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CCGEepjiV-Wx"
   },
   "source": [
    "Data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-o2yaPV5V8kz"
   },
   "outputs": [],
   "source": [
    "class DataGen(keras.utils.Sequence):\n",
    "  def __init__(self, ids, path, batch_size=4, image_size=576):\n",
    "    self.ids = ids\n",
    "    self.path = path\n",
    "    self.batch_size = batch_size\n",
    "    self.image_size = image_size\n",
    "    self.on_epoch_end()\n",
    "\n",
    "  def __load__(self, id_name):\n",
    "    image_path_1 = os.path.join(self.path, id_name, \"images/\")\n",
    "    #the path is corresponding the uploaded file names\n",
    "    image_path_2 =[]\n",
    "    for file in os.listdir(image_path_1):\n",
    "      if file.endswith(\".tif\"): #file type corresponding to uploaded file type\n",
    "        filename=os.path.join(image_path_1, file)\n",
    "        image_path_2.append(filename)\n",
    "    image_path =sorted(image_path_2)[0] #use [0] to take path of the only image \n",
    "    ##print (image_path)\n",
    "\n",
    "    mask_path = os.path.join(self.path, id_name, \"masks/\")#\n",
    "    all_masks=[]\n",
    "    for file in os.listdir(mask_path):\n",
    "      if file.endswith(\".tif\"):\n",
    "        all_masks.append(file)\n",
    "\n",
    "    #Reading images\n",
    "    image = cv2.imread(image_path, 0) \n",
    "    #flag=1: depth=8, channel=3, but I would like to change it to grayscale image\n",
    "    #if flag=1, then the image.shape=(577,577,3)\n",
    "    #flg = 0, image.shape=(576, 576):grayscale image\n",
    "    image = cv2.resize(image, (self.image_size, self.image_size))\n",
    "    image = np.array(image) #make it as numpy array\n",
    "    image=img_as_float(image) #change image type to float\n",
    "\n",
    "    ## Reading Masks\n",
    "    boundary_mask_path= mask_path+sorted(all_masks)[0]\n",
    "    interior_mask_path=mask_path+sorted(all_masks)[1]\n",
    "    junk_mask_path=mask_path+ sorted(all_masks)[2]\n",
    "    #must be noticed that [0],[1],[2] corresponds to the name of the mask of 1 image;\n",
    "    #file with \"__bound\": the first be extracted; __interior: 2nd; __junk: third\n",
    "\n",
    "    ##print (\"boundarymaskpath:\"+boundary_mask_path)\n",
    "\n",
    "    boundary_mask= cv2.imread(boundary_mask_path, 0)\n",
    "    interior_mask= cv2.imread(interior_mask_path, 0)\n",
    "    junk_mask=cv2.imread(junk_mask_path, 0)\n",
    "\n",
    "    boundary_mask=np.array(boundary_mask)\n",
    "    interior_mask=np.array(interior_mask)\n",
    "    junk_mask=np.array(junk_mask)\n",
    "\n",
    "    boundary=boundary_mask\n",
    "    interior=interior_mask/2.0\n",
    "    junk=junk_mask/4.0\n",
    "    #chage the pixel value of the mask images to make different regions have different values:\n",
    "\n",
    "    mask_0 = np.maximum(boundary, interior)\n",
    "    mask = np.maximum(mask_0, junk)\n",
    "    ##for use the boudanry only: \n",
    "    #mask = boundary_mask\n",
    "    mask = cv2.resize(mask, (self.image_size, self.image_size))\n",
    "\n",
    "    #Normalizing:\n",
    "    image *= 255.0/image.max()\n",
    "    image=image/255.0\n",
    "    mask=mask/255.0  \n",
    "\n",
    "    return image, mask\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    if(index+1)*self.batch_size > len(self.ids):\n",
    "      self.batch_size = len(self.ids) - index*self.batch_size\n",
    "    files_batch = self.ids[index*self.batch_size : (index+1)*self.batch_size]\n",
    "    #print (\"files_batch=\"+ str(files_batch))\n",
    "\n",
    "    image = []\n",
    "    mask = []\n",
    "\n",
    "    for id_name in files_batch:\n",
    "      _img, _msk = self.__load__(id_name)\n",
    "      image.append(_img)\n",
    "      mask.append(_msk)\n",
    "\n",
    "    image = np.array(image)\n",
    "    mask = np.array(mask)\n",
    "    #a=image.shape\n",
    "    #print (\"shape of image\"+str(a))\n",
    "\n",
    "    return image, mask\n",
    "  \n",
    "  def on_epoch_end(self):\n",
    "    pass\n",
    "  \n",
    "  def __len__(self):\n",
    "    return int(np.ceil(len(self.ids)/float(self.batch_size)))\n",
    "    #some bug are due to this code when training the model \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TH1UUHGW7bsS"
   },
   "source": [
    "Unzip zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a14kQD9sYQQr"
   },
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('./content/images_training.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('./content')\n",
    "#the path should be conrespond to the file name uploaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pbu037lx_YQj"
   },
   "outputs": [],
   "source": [
    "#the following check is used for check\n",
    "os.listdir('./content/images_training/train/a6/masks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KNxVs5xJ7zZZ"
   },
   "source": [
    "Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IthOpv5r7yr6"
   },
   "outputs": [],
   "source": [
    "image_size = 576\n",
    "# 576 is a good number for CNN\n",
    "train_path ='./content/images_training/train'\n",
    "#train_path corresponds to uploaded files\n",
    "epochs=100\n",
    "batch_size = 4\n",
    "\n",
    "# Training ids\n",
    "train_ids = next(os.walk(train_path))[1]\n",
    "#return the file dir in train_path\n",
    "\n",
    "## Validation Data size\n",
    "val_data_size = 12 #need to change later\n",
    "\n",
    "valid_ids = train_ids[:val_data_size]\n",
    "train_ids = train_ids[val_data_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3901,
     "status": "ok",
     "timestamp": 1596029368424,
     "user": {
      "displayName": "Jiayi Li",
      "photoUrl": "",
      "userId": "04192840362191936784"
     },
     "user_tz": -480
    },
    "id": "bxDV7EjZy88L",
    "outputId": "01efcaf7-168d-4f72-b417-b2d109a492a8"
   },
   "outputs": [],
   "source": [
    "print(train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3894,
     "status": "ok",
     "timestamp": 1596029368425,
     "user": {
      "displayName": "Jiayi Li",
      "photoUrl": "",
      "userId": "04192840362191936784"
     },
     "user_tz": -480
    },
    "id": "rmJB3xE58i6z",
    "outputId": "7af95a22-469f-49ad-9b80-f792e5d218df"
   },
   "outputs": [],
   "source": [
    "gen = DataGen(train_ids, train_path, batch_size=batch_size, image_size=image_size)\n",
    "x, y = gen.__getitem__(0)\n",
    "print(x.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4514,
     "status": "ok",
     "timestamp": 1596029369053,
     "user": {
      "displayName": "Jiayi Li",
      "photoUrl": "",
      "userId": "04192840362191936784"
     },
     "user_tz": -480
    },
    "id": "X8BLacWYHXXZ",
    "outputId": "d473a43a-8b48-48d0-f5c0-a1272df5a1fd"
   },
   "outputs": [],
   "source": [
    "#show the train image with masks:\n",
    "r = random.randint(0, len(x)-1)\n",
    "# Not sure what are they doing here: random.randint\n",
    "fig = plt.figure()\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.imshow(x[r])\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.imshow(np.reshape(y[r], (image_size, image_size)), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LGcHgMzNJX-r"
   },
   "source": [
    "Different Convolutional Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AGEXh-qFJV_R"
   },
   "outputs": [],
   "source": [
    "def down_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
    "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(x)\n",
    "    #x: the input\n",
    "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n",
    "    p = keras.layers.MaxPool2D((2, 2), (2, 2))(c)\n",
    "    return c, p\n",
    "\n",
    "def up_block(x, skip, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
    "    us = keras.layers.UpSampling2D((2, 2))(x)\n",
    "    concat = keras.layers.Concatenate()([us, skip])\n",
    "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(concat)\n",
    "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n",
    "    return c\n",
    "\n",
    "def bottleneck(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
    "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(x)\n",
    "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0clTDjNOdN7R"
   },
   "source": [
    "UNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zmmtu_59dJSb"
   },
   "outputs": [],
   "source": [
    "def UNet():\n",
    "    f = [8, 16, 32, 64, 128]\n",
    "    inputs = keras.layers.Input((576, 576, 1))\n",
    "    \n",
    "    p0 = inputs\n",
    "    c1, p1 = down_block(p0, f[0]) #128 -> 64\n",
    "    c2, p2 = down_block(p1, f[1]) #64 -> 32\n",
    "    c3, p3 = down_block(p2, f[2]) #32 -> 16\n",
    "    c4, p4 = down_block(p3, f[3]) #16->8\n",
    "    \n",
    "    bn = bottleneck(p4, f[4])\n",
    "    \n",
    "    u1 = up_block(bn, c4, f[3]) #8 -> 16\n",
    "    u2 = up_block(u1, c3, f[2]) #16 -> 32\n",
    "    u3 = up_block(u2, c2, f[1]) #32 -> 64\n",
    "    u4 = up_block(u3, c1, f[0]) #64 -> 128\n",
    "    \n",
    "    outputs = keras.layers.Conv2D(1, (1, 1), padding=\"same\", activation=\"sigmoid\")(u4)\n",
    "    model = keras.models.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13831,
     "status": "ok",
     "timestamp": 1596029378382,
     "user": {
      "displayName": "Jiayi Li",
      "photoUrl": "",
      "userId": "04192840362191936784"
     },
     "user_tz": -480
    },
    "id": "g5lhwtMKdSLH",
    "outputId": "ddbcef2b-3afe-42c0-c344-e4e1cf84834f"
   },
   "outputs": [],
   "source": [
    "model = UNet()\n",
    "model.compile(optimizer=\"adam\", loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False), metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13824,
     "status": "ok",
     "timestamp": 1596029378383,
     "user": {
      "displayName": "Jiayi Li",
      "photoUrl": "",
      "userId": "04192840362191936784"
     },
     "user_tz": -480
    },
    "id": "gAfSwb-N-T2S",
    "outputId": "5e4d8b90-cfe1-45d0-897f-610f9fe4f8bf"
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 162006,
     "status": "ok",
     "timestamp": 1596029526573,
     "user": {
      "displayName": "Jiayi Li",
      "photoUrl": "",
      "userId": "04192840362191936784"
     },
     "user_tz": -480
    },
    "id": "yDnMIaII0PiJ",
    "outputId": "5cffc307-5655-470f-b4d5-c4d72e4b2e95"
   },
   "outputs": [],
   "source": [
    "train_gen = DataGen(train_ids, train_path, image_size=image_size, batch_size=batch_size)\n",
    "valid_gen = DataGen(valid_ids, train_path, image_size=image_size, batch_size=batch_size)\n",
    "\n",
    "train_steps = len(train_ids)//batch_size\n",
    "valid_steps = len(valid_ids)//batch_size\n",
    "\n",
    "model.fit_generator(train_gen, validation_data=valid_gen, steps_per_epoch=train_steps, validation_steps=valid_steps, \n",
    "                    epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H6bh9EliTOfg"
   },
   "source": [
    "Testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 164252,
     "status": "ok",
     "timestamp": 1596029528827,
     "user": {
      "displayName": "Jiayi Li",
      "photoUrl": "",
      "userId": "04192840362191936784"
     },
     "user_tz": -480
    },
    "id": "8eGazRiAj7h_",
    "outputId": "358f7628-3d52-4d0f-cf3a-bc1fc5fc8ebe"
   },
   "outputs": [],
   "source": [
    "#save the model for further independent use:\n",
    "model.save('./content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eYivil1OlIVg"
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model('./content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 165655,
     "status": "ok",
     "timestamp": 1596029530241,
     "user": {
      "displayName": "Jiayi Li",
      "photoUrl": "",
      "userId": "04192840362191936784"
     },
     "user_tz": -480
    },
    "id": "sArXQa9DWzWg",
    "outputId": "e8145fdf-acaf-48af-a874-3811c2c31c85"
   },
   "outputs": [],
   "source": [
    "## Dataset for prediction\n",
    "x, y = valid_gen.__getitem__(0)\n",
    "result = model.predict(x)\n",
    "result.shape\n",
    "#result = result > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 166042,
     "status": "ok",
     "timestamp": 1596029530635,
     "user": {
      "displayName": "Jiayi Li",
      "photoUrl": "",
      "userId": "04192840362191936784"
     },
     "user_tz": -480
    },
    "id": "hOq7yYLGTXAH",
    "outputId": "09849c99-62e8-405e-8e1a-4d372aac0fab"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.imshow(np.reshape(y[1]*255, (image_size, image_size)), cmap=\"gray\")\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.imshow(np.reshape(result[1]*255, (image_size, image_size)), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EvuR0c3Ek8KO"
   },
   "source": [
    "Part 2: Make Prediction: Image quantification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PTjS7W0AUjP4"
   },
   "outputs": [],
   "source": [
    "import skimage\n",
    "from skimage import img_as_ubyte\n",
    "from skimage import img_as_float\n",
    "from skimage import morphology\n",
    "from skimage.morphology import square\n",
    "from skimage import measure\n",
    "from scipy import ndimage\n",
    "from scipy.ndimage import label, generate_binary_structure\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZsAiXNPuk7kd"
   },
   "outputs": [],
   "source": [
    "#import image and normalize it:\n",
    "Predicting_image_path='./content/vps26a-2 RGS1-YFP 0 min 6_ gluc 5.tif'\n",
    "#notice: the image_path corresponds to certain image;\n",
    "##for desinging user interface, image_path should be automatically as the imagepath of the image imported by the user.\n",
    "##also could design for batch prediction\n",
    "\n",
    "image_path=Predicting_image_path\n",
    "image = cv2.imread(image_path, 0)\n",
    "image = cv2.resize(image, (576, 576))\n",
    "image=img_as_float(image)\n",
    "image *= 255.0/image.max()\n",
    "image=image/255.0\n",
    "#related to whether the image normalized\n",
    "image = np.array(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 941,
     "status": "ok",
     "timestamp": 1596029628490,
     "user": {
      "displayName": "Jiayi Li",
      "photoUrl": "",
      "userId": "04192840362191936784"
     },
     "user_tz": -480
    },
    "id": "n0_4u187nT4J",
    "outputId": "46255967-1cdd-45e8-d408-6447c6e45f08"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(576, 576)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 934,
     "status": "ok",
     "timestamp": 1596029628490,
     "user": {
      "displayName": "Jiayi Li",
      "photoUrl": "",
      "userId": "04192840362191936784"
     },
     "user_tz": -480
    },
    "id": "-WR94hf87KO4",
    "outputId": "39f700d2-ecc9-4ceb-857d-ee544d6871e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 576, 576)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.expand_dims(image, axis=0)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 928,
     "status": "ok",
     "timestamp": 1596029628491,
     "user": {
      "displayName": "Jiayi Li",
      "photoUrl": "",
      "userId": "04192840362191936784"
     },
     "user_tz": -480
    },
    "id": "ngvkUMqe9Z2L",
    "outputId": "793f7423-e6c3-41c0-8ade-79cb8b338537"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 576, 576, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.predict(y)\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1499,
     "status": "ok",
     "timestamp": 1596029629070,
     "user": {
      "displayName": "Jiayi Li",
      "photoUrl": "",
      "userId": "04192840362191936784"
     },
     "user_tz": -480
    },
    "id": "JfjjYiLA9yMh",
    "outputId": "edbefc59-0b5b-42c4-f2a8-74d2f5f4e474"
   },
   "outputs": [],
   "source": [
    "img=mpimg.imread(image_path)\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1492,
     "status": "ok",
     "timestamp": 1596029629071,
     "user": {
      "displayName": "Jiayi Li",
      "photoUrl": "",
      "userId": "04192840362191936784"
     },
     "user_tz": -480
    },
    "id": "OY-YVCLn9fpq",
    "outputId": "c1ebae33-4ba9-4e5e-8713-dab2b4a14c03"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.imshow(np.reshape(result[0]*255, (image_size, image_size)), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nrq_Mm5K39qD"
   },
   "source": [
    "Image quantificaton:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fspYj3SG5DoL"
   },
   "outputs": [],
   "source": [
    "result= np.squeeze(result, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1479,
     "status": "ok",
     "timestamp": 1596029629073,
     "user": {
      "displayName": "Jiayi Li",
      "photoUrl": "",
      "userId": "04192840362191936784"
     },
     "user_tz": -480
    },
    "id": "gU--_M8g5L97",
    "outputId": "5e1d0d71-8080-4a3f-9232-d620b5abc7d6"
   },
   "outputs": [],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a3t4LWKQ5Ud1"
   },
   "outputs": [],
   "source": [
    "result= np.squeeze(result, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1466,
     "status": "ok",
     "timestamp": 1596029629074,
     "user": {
      "displayName": "Jiayi Li",
      "photoUrl": "",
      "userId": "04192840362191936784"
     },
     "user_tz": -480
    },
    "id": "1AvnpNac5aWq",
    "outputId": "ab0626ba-6ec7-47e2-9c08-0eebc07f4197"
   },
   "outputs": [],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1460,
     "status": "ok",
     "timestamp": 1596029629075,
     "user": {
      "displayName": "Jiayi Li",
      "photoUrl": "",
      "userId": "04192840362191936784"
     },
     "user_tz": -480
    },
    "id": "Oag7DJ505iM-",
    "outputId": "385de6b6-495a-4751-c9a2-80f250d79935"
   },
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1930,
     "status": "ok",
     "timestamp": 1596029629553,
     "user": {
      "displayName": "Jiayi Li",
      "photoUrl": "",
      "userId": "04192840362191936784"
     },
     "user_tz": -480
    },
    "id": "68GohyuY5wUg",
    "outputId": "0cee9332-b3c5-4295-b2fa-d8a5b270cdaf"
   },
   "outputs": [],
   "source": [
    "plt.imshow(result, cmap = 'gray', interpolation = 'bicubic')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EFi_ZNnqVxoF"
   },
   "outputs": [],
   "source": [
    "prediction_data=result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u_OQN2pm8qQ2"
   },
   "outputs": [],
   "source": [
    "#only show the boundary:\n",
    "prediction_data[prediction_data >= 0.7] = 1\n",
    "prediction_data[prediction_data < 0.7] = 0 \n",
    "\n",
    "## Critical: must notice the output of CNN is pixel with continous numbers:\n",
    "# higher accuracy, the closer it is to the pixel values designated in masks.\n",
    "# thus, the number \"0.6\" made here is arbitary, depends on the accuracy of CNN, if Accuracy is high, it should be close to 1.0\n",
    "### could influence the quantification result by thining or expending the boundary/membrane areas\n",
    "\n",
    "## could also find ways to show other ROI predicted to make more options for the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1913,
     "status": "ok",
     "timestamp": 1596029629555,
     "user": {
      "displayName": "Jiayi Li",
      "photoUrl": "",
      "userId": "04192840362191936784"
     },
     "user_tz": -480
    },
    "id": "GoFTxOQmByYx",
    "outputId": "3063a856-0f2c-4e33-df70-cfc9238abe19"
   },
   "outputs": [],
   "source": [
    "plt.imshow(prediction_data, cmap = 'gray', interpolation = 'bicubic')\n",
    "plt.xticks([]), plt.yticks([]) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1906,
     "status": "ok",
     "timestamp": 1596029629556,
     "user": {
      "displayName": "Jiayi Li",
      "photoUrl": "",
      "userId": "04192840362191936784"
     },
     "user_tz": -480
    },
    "id": "PglXIv1raYxv",
    "outputId": "2e529fb0-1017-4e67-cc26-5f79a20825a6"
   },
   "outputs": [],
   "source": [
    "prediction_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LvPcEa8bVlCD"
   },
   "outputs": [],
   "source": [
    "prediction_data = prediction_data.astype('int')\n",
    "prediction_data = morphology.remove_small_objects(prediction_data.astype(bool),64)\n",
    "prediction_data = prediction_data.astype('float32') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RY_7gbLdXRB1"
   },
   "outputs": [],
   "source": [
    "prediction_data = skimage.morphology.closing(prediction_data, square(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qbQyxEIrXjlP"
   },
   "outputs": [],
   "source": [
    "ROW= [0,1,2,3,4,5]\n",
    "for I in ROW:\n",
    "  prediction_data[I,:]=1\n",
    "  prediction_data[:,I]=1\n",
    "  prediction_data[-I,:]=1\n",
    "  prediction_data[:,-I]=1\n",
    "\n",
    "## add the row at the margin of image, because of bad annotation, the boundary in image margin would be miss classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7fweOCu9XsZ3"
   },
   "outputs": [],
   "source": [
    "prediction_data[prediction_data == 1.0] = 0.5\n",
    "prediction_data[prediction_data == 0.0] = 1.0\n",
    "prediction_data[prediction_data == 0.5] = 0.0\n",
    "\n",
    "#change the interior area to value 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i8FVXUwyYRmi"
   },
   "outputs": [],
   "source": [
    "s = generate_binary_structure(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_NVnd9cgX5ZC"
   },
   "outputs": [],
   "source": [
    "labeled_array, num_features = label(prediction_data, structure=s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1866,
     "status": "ok",
     "timestamp": 1596029629559,
     "user": {
      "displayName": "Jiayi Li",
      "photoUrl": "",
      "userId": "04192840362191936784"
     },
     "user_tz": -480
    },
    "id": "fU3SfpVKYFOd",
    "outputId": "438475a8-848b-4f4c-bea8-9d826fe05ce0"
   },
   "outputs": [],
   "source": [
    "num_features\n",
    "#how many ROI/unconnected object it find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1859,
     "status": "ok",
     "timestamp": 1596029629560,
     "user": {
      "displayName": "Jiayi Li",
      "photoUrl": "",
      "userId": "04192840362191936784"
     },
     "user_tz": -480
    },
    "id": "1VAH3ob5YKKb",
    "outputId": "ce086dd2-85f3-4476-c787-9d42b84137a9"
   },
   "outputs": [],
   "source": [
    "plt.imshow(labeled_array)\n",
    "#different colors conrespond to different labels (numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1852,
     "status": "ok",
     "timestamp": 1596029629560,
     "user": {
      "displayName": "Jiayi Li",
      "photoUrl": "",
      "userId": "04192840362191936784"
     },
     "user_tz": -480
    },
    "id": "ypFNClLTYZYR",
    "outputId": "ad63c133-874e-4f42-9f44-b62c81eff347"
   },
   "outputs": [],
   "source": [
    "unique, counts = np.unique(labeled_array, return_counts=True)\n",
    "dict(zip(unique, counts))\n",
    "#label (number) has 26669 pixels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2602,
     "status": "ok",
     "timestamp": 1596029630318,
     "user": {
      "displayName": "Jiayi Li",
      "photoUrl": "",
      "userId": "04192840362191936784"
     },
     "user_tz": -480
    },
    "id": "FqiDbfiaYdoa",
    "outputId": "f0981632-b779-41bd-f465-158212dd3383"
   },
   "outputs": [],
   "source": [
    "for i in range(num_features+1):\n",
    "  if np.count_nonzero(labeled_array == i)>1000: #discard small ROI\n",
    "    a = np.count_nonzero(labeled_array == i)\n",
    "    print('pixel area =',np.count_nonzero(labeled_array == i))\n",
    "    b = ndimage.sum(image, labeled_array, index=[i])\n",
    "    print('pixel intensity =',ndimage.sum(image, labeled_array, index=[i]))\n",
    "    arr_1 = (labeled_array == i).astype(int)\n",
    "    a1=np.roll(arr_1, 8, axis=0)\n",
    "    a2=np.roll(arr_1, -8, axis=0)\n",
    "    a3=np.roll(arr_1, 8, axis=1)\n",
    "    a4=np.roll(arr_1, -8, axis=1)\n",
    "    a5=a1+a2+a3+a4\n",
    "    a5[a5 > i-0.1] = 1\n",
    "    c= ndimage.sum(image, a5, index=[1])-b\n",
    "    print('pixel intensity in boundary =',c)\n",
    "    ##Critical: the value \"8\" in np.rool meas to expand the region i by 8 pixels\n",
    "    ## the value \"8\" corresponds to the length of the cell membranes.\n",
    "    ##Critical: the prediction accuracy of CNN also would influence the parameter used in np.rool:\n",
    "    ### also related to the parameter in \"#only show the boundary:\" lines\n",
    "\n",
    "    slice_x, slice_y = ndimage.find_objects(labeled_array == i)[0]\n",
    "    roi = labeled_array[slice_x, slice_y]\n",
    "    plt.figure()\n",
    "    plt.imshow(roi)\n",
    "    print('------')\n",
    "    #print(i)\n",
    "    #print(slice_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Copy of Deep learning speeds up image analysis.ipynb",
   "provenance": [
    {
     "file_id": "1iSQO3-j067QAqrrZEFnsNZa_8avTgake",
     "timestamp": 1596511809738
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
